This a RAG Pipeline for different llm models which are hosted using Ollama

llm models used : mistral, llama2, gemma2
Embedding models used : nomic_embed_text , mxbai-embed-large

Database for the embeddings: Chroma database (local)

The pipeline is run locally after pulling required embedding and llm models from Ollama

